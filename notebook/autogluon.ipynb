{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3e9b85b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from /home/jupyter/work/data/raw/train.csv\n",
      "Data Loaded. Shape: (700000, 25)\n",
      "Loading data from /home/jupyter/work/data/raw/test.csv\n",
      "Test X: (300000, 25)\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('../src'))\n",
    "\n",
    "from data_loader import DiabetesLoader, TestLoader\n",
    "\n",
    "loader = DiabetesLoader('../data/raw/train.csv')\n",
    "df = loader.get_df()\n",
    "\n",
    "test_loader = TestLoader('../data/raw/test.csv')\n",
    "test,id = test_loader.get_data() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0f1d88f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (700000, 25) (+1 from target)\n",
      "test shape: (300000, 24)\n"
     ]
    }
   ],
   "source": [
    "print(f\"train shape: {df.shape} (+1 from target)\")\n",
    "print(f\"test shape: {test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ae4044f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20251228_062721\"\n"
     ]
    }
   ],
   "source": [
    "from autogluon.tabular import TabularPredictor\n",
    "from config import TARGET\n",
    "\n",
    "predictor = TabularPredictor(label=TARGET, eval_metric='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "817730ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Dynamic stacking is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "Detecting stacked overfitting by sub-fitting AutoGluon on the input data. That is, copies of AutoGluon will be sub-fit on subset(s) of the data. Then, the holdout validation data is used to detect stacked overfitting.\n",
      "Sub-fit(s) time limit is: 900 seconds.\n",
      "Starting holdout-based sub-fit for dynamic stacking. Context path is: AutogluonModels/ag-20251228_062721/ds_sub_fit/sub_fit_ho.\n",
      "Beginning AutoGluon training ... Time limit = 225s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20251228_062721/ds_sub_fit/sub_fit_ho\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.0.0\n",
      "Python Version:     3.10.8\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP PREEMPT_DYNAMIC Thu Jun  5 18:30:46 UTC 2025\n",
      "CPU Count:          16\n",
      "Memory Avail:       4.38 GB / 7.66 GB (57.2%)\n",
      "Disk Space Avail:   710.67 GB / 931.50 GB (76.3%)\n",
      "===================================================\n",
      "Train Data Rows:    622222\n",
      "Train Data Columns: 24\n",
      "Label Column:       diagnosed_diabetes\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    4599.48 MB\n",
      "\tTrain Data (Original)  Memory Usage: 313.11 MB (6.8% of available memory)\n",
      "\tWarning: Data size prior to feature transformation consumes 6.8% of available memory. Consider increasing memory or subsampling the data to avoid instability.\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 3 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  :  5 | ['diet_score', 'sleep_hours_per_day', 'screen_time_hours_per_day', 'bmi', 'waist_to_hip_ratio']\n",
      "\t\t('int', [])    : 13 | ['age', 'alcohol_consumption_per_week', 'physical_activity_minutes_per_week', 'systolic_bp', 'diastolic_bp', ...]\n",
      "\t\t('object', []) :  6 | ['gender', 'ethnicity', 'education_level', 'income_level', 'smoking_status', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  :  6 | ['gender', 'ethnicity', 'education_level', 'income_level', 'smoking_status', ...]\n",
      "\t\t('float', [])     :  5 | ['diet_score', 'sleep_hours_per_day', 'screen_time_hours_per_day', 'bmi', 'waist_to_hip_ratio']\n",
      "\t\t('int', [])       : 10 | ['age', 'alcohol_consumption_per_week', 'physical_activity_minutes_per_week', 'systolic_bp', 'diastolic_bp', ...]\n",
      "\t\t('int', ['bool']) :  3 | ['family_history_diabetes', 'hypertension_history', 'cardiovascular_history']\n",
      "\t3.9s = Fit runtime\n",
      "\t24 features in original data used to generate 24 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 76.55 MB (1.7% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 4.29s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
      "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 110 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 147.1s of the 220.68s of remaining time.\n",
      "\t0.5794\t = Validation score   (roc_auc)\n",
      "\t5.76s\t = Training   runtime\n",
      "\t111.04s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 28.15s of the 101.74s of remaining time.\n",
      "\tNot enough time to generate out-of-fold predictions for model. Estimated time required was 166.3s compared to 31.41s of available time.\n",
      "\tTime limit exceeded... Skipping KNeighborsDist_BAG_L1.\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 22.47s of the 96.06s of remaining time.\n",
      "Will use sequential fold fitting strategy because import of ray failed. Reason: ray==2.9.3 detected. 2.6.3 <= ray < 2.7.0 is required. You can use pip to install certain version of ray `pip install ray==2.6.3` \n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, early stopping on iteration 58. Best iteration is:\n",
      "\t[58]\tvalid_set's binary_logloss: 0.603698\n",
      "\tTime limit exceeded... Skipping LightGBMXT_BAG_L1.\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 19.2s of the 92.78s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, early stopping on iteration 53. Best iteration is:\n",
      "\t[53]\tvalid_set's binary_logloss: 0.598502\n",
      "\tTime limit exceeded... Skipping LightGBM_BAG_L1.\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 16.44s of the 90.02s of remaining time.\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 242 due to low memory. Expected memory usage reduced from 18.59% -> 15.0% of available memory...\n",
      "\tWarning: Model is expected to require 174.5s to train, which exceeds the maximum time limit of 16.4s, skipping model...\n",
      "\tTime limit exceeded... Skipping RandomForestGini_BAG_L1.\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 12.97s of the 86.56s of remaining time.\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 241 due to low memory. Expected memory usage reduced from 18.63% -> 15.0% of available memory...\n",
      "\tWarning: Model is expected to require 198.0s to train, which exceeds the maximum time limit of 13.0s, skipping model...\n",
      "\tTime limit exceeded... Skipping RandomForestEntr_BAG_L1.\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 9.14s of the 82.72s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, early stopping on iteration 1.\n",
      "\tTime limit exceeded... Skipping CatBoost_BAG_L1.\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 7.16s of the 80.75s of remaining time.\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 205 due to low memory. Expected memory usage reduced from 21.87% -> 15.0% of available memory...\n",
      "\tWarning: Model is expected to require 149.3s to train, which exceeds the maximum time limit of 7.2s, skipping model...\n",
      "\tTime limit exceeded... Skipping ExtraTreesGini_BAG_L1.\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 3.68s of the 77.26s of remaining time.\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 205 due to low memory. Expected memory usage reduced from 21.94% -> 15.0% of available memory...\n",
      "\tWarning: Model is expected to require 73.5s to train, which exceeds the maximum time limit of 3.7s, skipping model...\n",
      "\tTime limit exceeded... Skipping ExtraTreesEntr_BAG_L1.\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 1.67s of the 75.26s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tTime limit exceeded... Skipping NeuralNetFastAI_BAG_L1.\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 220.71s of the 58.07s of remaining time.\n",
      "\tEnsemble Weights: {'KNeighborsUnif_BAG_L1': 1.0}\n",
      "\t0.5794\t = Validation score   (roc_auc)\n",
      "\t0.08s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting 108 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 57.68s of the 57.57s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, early stopping on iteration 143. Best iteration is:\n",
      "\t[143]\tvalid_set's binary_logloss: 0.599063\n",
      "\tRan out of time, early stopping on iteration 164. Best iteration is:\n",
      "\t[164]\tvalid_set's binary_logloss: 0.601362\n",
      "\tRan out of time, early stopping on iteration 220. Best iteration is:\n",
      "\t[220]\tvalid_set's binary_logloss: 0.597772\n",
      "\tRan out of time, early stopping on iteration 167. Best iteration is:\n",
      "\t[167]\tvalid_set's binary_logloss: 0.601762\n",
      "\tRan out of time, early stopping on iteration 178. Best iteration is:\n",
      "\t[178]\tvalid_set's binary_logloss: 0.599729\n",
      "\tRan out of time, early stopping on iteration 211. Best iteration is:\n",
      "\t[211]\tvalid_set's binary_logloss: 0.598255\n",
      "\tRan out of time, early stopping on iteration 319. Best iteration is:\n",
      "\t[319]\tvalid_set's binary_logloss: 0.59719\n",
      "\tRan out of time, early stopping on iteration 279. Best iteration is:\n",
      "\t[279]\tvalid_set's binary_logloss: 0.598953\n",
      "\t0.7003\t = Validation score   (roc_auc)\n",
      "\t53.37s\t = Training   runtime\n",
      "\t1.88s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 220.71s of the -2.8s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L2': 1.0}\n",
      "\t0.7003\t = Validation score   (roc_auc)\n",
      "\t36.18s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 265.59s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20251228_062721/ds_sub_fit/sub_fit_ho\")\n",
      "Leaderboard on holdout data from dynamic stacking:\n",
      "                   model  holdout_score  score_val eval_metric  pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0      LightGBMXT_BAG_L2       0.701137   0.700270     roc_auc       17.425523     112.920491  59.129391                 1.933503                1.882565          53.366550            2       True          3\n",
      "1    WeightedEnsemble_L3       0.701137   0.700270     roc_auc       17.445285     113.090603  95.313038                 0.019762                0.170112          36.183647            3       True          4\n",
      "2  KNeighborsUnif_BAG_L1       0.577630   0.579395     roc_auc       15.492020     111.037926   5.762841                15.492020              111.037926           5.762841            1       True          1\n",
      "3    WeightedEnsemble_L2       0.577630   0.579395     roc_auc       15.504049     111.115382   5.839097                 0.012029                0.077456           0.076255            2       True          2\n",
      "Stacked overfitting occurred: False.\n",
      "Spend 285 seconds for the sub-fit(s) during dynamic stacking.\n",
      "Time left for full fit of AutoGluon: 615 seconds.\n",
      "Starting full fit now with num_stack_levels 1.\n",
      "Beginning AutoGluon training ... Time limit = 615s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20251228_062721\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.0.0\n",
      "Python Version:     3.10.8\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP PREEMPT_DYNAMIC Thu Jun  5 18:30:46 UTC 2025\n",
      "CPU Count:          16\n",
      "Memory Avail:       3.01 GB / 7.66 GB (39.3%)\n",
      "Disk Space Avail:   710.67 GB / 931.50 GB (76.3%)\n",
      "===================================================\n",
      "Train Data Rows:    700000\n",
      "Train Data Columns: 24\n",
      "Label Column:       diagnosed_diabetes\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3331.08 MB\n",
      "\tTrain Data (Original)  Memory Usage: 352.25 MB (10.6% of available memory)\n",
      "\tWarning: Data size prior to feature transformation consumes 10.6% of available memory. Consider increasing memory or subsampling the data to avoid instability.\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 3 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  :  5 | ['diet_score', 'sleep_hours_per_day', 'screen_time_hours_per_day', 'bmi', 'waist_to_hip_ratio']\n",
      "\t\t('int', [])    : 13 | ['age', 'alcohol_consumption_per_week', 'physical_activity_minutes_per_week', 'systolic_bp', 'diastolic_bp', ...]\n",
      "\t\t('object', []) :  6 | ['gender', 'ethnicity', 'education_level', 'income_level', 'smoking_status', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  :  6 | ['gender', 'ethnicity', 'education_level', 'income_level', 'smoking_status', ...]\n",
      "\t\t('float', [])     :  5 | ['diet_score', 'sleep_hours_per_day', 'screen_time_hours_per_day', 'bmi', 'waist_to_hip_ratio']\n",
      "\t\t('int', [])       : 10 | ['age', 'alcohol_consumption_per_week', 'physical_activity_minutes_per_week', 'systolic_bp', 'diastolic_bp', ...]\n",
      "\t\t('int', ['bool']) :  3 | ['family_history_diabetes', 'hypertension_history', 'cardiovascular_history']\n",
      "\t6.3s = Fit runtime\n",
      "\t24 features in original data used to generate 24 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 86.12 MB (2.6% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 6.73s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
      "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 110 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 405.41s of the 608.25s of remaining time.\n",
      "\t0.5791\t = Validation score   (roc_auc)\n",
      "\t6.84s\t = Training   runtime\n",
      "\t134.41s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 261.34s of the 464.18s of remaining time.\n",
      "\t0.5792\t = Validation score   (roc_auc)\n",
      "\t6.87s\t = Training   runtime\n",
      "\t140.31s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 111.27s of the 314.11s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, early stopping on iteration 457. Best iteration is:\n",
      "\t[457]\tvalid_set's binary_logloss: 0.598055\n",
      "\tRan out of time, early stopping on iteration 370. Best iteration is:\n",
      "\t[370]\tvalid_set's binary_logloss: 0.596993\n",
      "\tRan out of time, early stopping on iteration 519. Best iteration is:\n",
      "\t[519]\tvalid_set's binary_logloss: 0.598405\n",
      "\tRan out of time, early stopping on iteration 438. Best iteration is:\n",
      "\t[438]\tvalid_set's binary_logloss: 0.598116\n",
      "\tRan out of time, early stopping on iteration 531. Best iteration is:\n",
      "\t[531]\tvalid_set's binary_logloss: 0.598479\n",
      "\tRan out of time, early stopping on iteration 380. Best iteration is:\n",
      "\t[380]\tvalid_set's binary_logloss: 0.59749\n",
      "\tRan out of time, early stopping on iteration 432. Best iteration is:\n",
      "\t[432]\tvalid_set's binary_logloss: 0.597548\n",
      "\tRan out of time, early stopping on iteration 630. Best iteration is:\n",
      "\t[630]\tvalid_set's binary_logloss: 0.597811\n",
      "\t0.7027\t = Validation score   (roc_auc)\n",
      "\t103.32s\t = Training   runtime\n",
      "\t4.66s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 2.04s of the 204.88s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, early stopping on iteration 1. Best iteration is:\n",
      "\t[1]\tvalid_set's binary_logloss: 0.657406\n",
      "\tTime limit exceeded... Skipping LightGBM_BAG_L1.\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 200.12s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 0.989, 'KNeighborsUnif_BAG_L1': 0.011}\n",
      "\t0.7027\t = Validation score   (roc_auc)\n",
      "\t58.12s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting 108 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 141.61s of the 142.0s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, early stopping on iteration 506. Best iteration is:\n",
      "\t[504]\tvalid_set's binary_logloss: 0.596138\n",
      "\tRan out of time, early stopping on iteration 679. Best iteration is:\n",
      "\t[679]\tvalid_set's binary_logloss: 0.596541\n",
      "\tRan out of time, early stopping on iteration 590. Best iteration is:\n",
      "\t[590]\tvalid_set's binary_logloss: 0.5958\n",
      "\tRan out of time, early stopping on iteration 709. Best iteration is:\n",
      "\t[709]\tvalid_set's binary_logloss: 0.596138\n",
      "\tRan out of time, early stopping on iteration 625. Best iteration is:\n",
      "\t[625]\tvalid_set's binary_logloss: 0.597657\n",
      "\tRan out of time, early stopping on iteration 781. Best iteration is:\n",
      "\t[781]\tvalid_set's binary_logloss: 0.59761\n",
      "\tRan out of time, early stopping on iteration 715. Best iteration is:\n",
      "\t[715]\tvalid_set's binary_logloss: 0.597485\n",
      "\tRan out of time, early stopping on iteration 949. Best iteration is:\n",
      "\t[948]\tvalid_set's binary_logloss: 0.596841\n",
      "\t0.7047\t = Validation score   (roc_auc)\n",
      "\t132.76s\t = Training   runtime\n",
      "\t4.49s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the 1.11s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L2': 1.0}\n",
      "\t0.7047\t = Validation score   (roc_auc)\n",
      "\t76.07s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 691.58s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20251228_062721\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<autogluon.tabular.predictor.predictor.TabularPredictor at 0x7eecda6535b0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.fit(\n",
    "    train_data=df, \n",
    "    presets='best_quality',\n",
    "    # excluded_model_types=['RF', 'XT', 'KNN', 'NN_TORCH'],\n",
    "    time_limit=900  # 15 minutes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a523cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "predictions = predictor.predict_proba(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06cca658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            id  diagnosed_diabetes\n",
      "0       700000            0.541286\n",
      "1       700001            0.596761\n",
      "2       700002            0.680291\n",
      "3       700003            0.515751\n",
      "4       700004            0.884711\n",
      "...        ...                 ...\n",
      "299995  999995            0.728116\n",
      "299996  999996            0.637711\n",
      "299997  999997            0.584599\n",
      "299998  999998            0.621204\n",
      "299999  999999            0.556383\n",
      "\n",
      "[300000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "submission = pd.DataFrame({\n",
    "    'id': id,\n",
    "    TARGET: predictions[1] \n",
    "})\n",
    "\n",
    "print(submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4242a691",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('../outputs/autogluon_full_roc_auc.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
